---
title: "SetFit : Fine-Tuning Efficace des Transformers de Phrases pour la Classification"
publishedAt: "2025-01-31"
summary: "Une approche combinant Few-Shot Learning et Apprentissage Contrastif pour améliorer la classification de texte avec des données limitées."
tag: "Science des données"
---

## **Introduction**

Les transformers de phrases sont une avancée majeure en NLP, permettant de convertir du texte en représentations vectorielles riches. Ces embeddings facilitent des tâches comme l'analyse de sentiment et la classification de texte.

Cependant, le fine-tuning de ces modèles nécessite généralement de grandes quantités de données et de puissantes ressources de calcul. **SetFit** (Sentence Transformer Fine-Tuning) répond à ce défi en combinant **Few-Shot Learning** et **Apprentissage Contrastif** pour optimiser l'apprentissage tout en réduisant les besoins en données et en puissance.

---

## **Problème du Fine-Tuning des Transformers**

L'entraînement classique des transformers repose sur de vastes quantités de données annotées, ce qui limite leur adaptabilité dans des contextes spécifiques où les ressources sont restreintes. L'acquisition de ces données peut être coûteuse et longue.

---

## **Combinaison du Few-Shot Learning et de l'Apprentissage Contrastif**

### **1. Few-Shot Learning**

Le Few-Shot Learning permet aux modèles de s’adapter avec seulement quelques exemples en tirant parti de connaissances préexistantes. Cela est particulièrement utile lorsque les données annotées sont rares.

### **2. Apprentissage Contrastif**

L'Apprentissage Contrastif aide à différencier les phrases similaires et dissemblables en ajustant les représentations vectorielles, ce qui améliore considérablement la qualité des embeddings.

---

## **Qu'est-ce que SetFit ?**

SetFit est un framework qui simplifie l’adaptation des sentence transformers aux tâches de classification en :

- Facilitant l'entraînement avec un faible volume de données.
- Améliorant la précision de la classification.
- Réduisant le temps et les coûts d’entraînement.

---

## **Benchmarking de SetFit**

Malgré des modèles plus petits, SetFit rivalise avec des approches comme GPT-3 et PET. Sur le benchmark **RAFT Few-Shot Classification**, SetFit avec RoBERTa (355M paramètres) dépasse les performances humaines de base sur 7 des 11 tâches évaluées.

### **Performance et coûts**

SetFit se distingue par sa rapidité et son coût réduit. Par exemple :
- Entraîner **SetFit** avec une **NVIDIA V100** et **8 échantillons** prend seulement **30 secondes** pour un coût de **0,025$**.
- En comparaison, **T-Few 3B**, un modèle bien plus grand, nécessite **11 minutes** d'entraînement sur une **NVIDIA A100** et coûte environ **0,7$**.

De plus, SetFit offre un **gain de vitesse d’inférence jusqu’à 123 fois supérieur** par rapport aux modèles massifs, tout en maintenant une précision comparable.

---

## **Fonctionnement de SetFit**

### **1. Fine-Tuning du Sentence Transformer**
- Génère des paires de phrases positives et négatives pour affiner les embeddings.

### **2. Entraînement de la Couche de Classification**
- Encode les phrases et applique une régression logistique pour la classification finale.

### **3. Génération des Paires de Phrases**
- Associe une phrase à une phrase de sens similaire (*positive pair*).
- Associe une phrase à une phrase de sens différent (*negative pair*).

---

## **Implémentation en Python**

```python
# Installation des bibliothèques
!pip install setfit optuna

# Import des modules
from setfit import TrainingArguments, Trainer, sample_dataset, SetFitModel
from sentence_transformers import SentenceTransformer
from sklearn.linear_model import LogisticRegression
from datasets import Dataset

# Chargement et préparation des données
train_dataset = Dataset.from_pandas(train)
test_dataset = Dataset.from_pandas(test)
train_dataset = sample_dataset(train_dataset, label_column="category_encoded", num_samples=8)

# Définition du modèle
model_body = SentenceTransformer("paraphrase-mpnet-base-v2")
model_head = LogisticRegression()
model = SetFitModel(model_body, model_head)

# Entraînement du modèle
args = TrainingArguments(batch_size=32, num_epochs=2, end_to_end=True)
trainer = Trainer(model=model, args=args, train_dataset=train_dataset,
column_mapping={"X_col": "text", "category_encoded": "label"})
trainer.train()
trainer.evaluate(test_dataset)
```

---

## **Optimisation des Hyperparamètres**

```python
from optuna import Trial

def model_init(params):
    params = params or {}
    return SetFitModel.from_pretrained("BAAI/bge-small-en-v1.5", head_params=params)

def hp_space(trial: Trial):
    return {
        "body_learning_rate": trial.suggest_float("body_learning_rate", 1e-6, 1e-3, log=True),
        "num_epochs": trial.suggest_int("num_epochs", 1, 3),
        "batch_size": trial.suggest_categorical("batch_size", [16, 32, 64]),
    }

trainer = Trainer(train_dataset=train_dataset, eval_dataset=test_dataset, model_init=model_init)
best_run = trainer.hyperparameter_search(direction="maximize", hp_space=hp_space, n_trials=10)
trainer.apply_hyperparameters(best_run.hyperparameters, final_model=True)
trainer.train()
metrics = trainer.evaluate()
```

---

## **Conclusion**

SetFit est une approche puissante et efficace pour la classification de texte, combinant **sentence transformers** et **apprentissage contrastif**. Il permet d’obtenir des résultats comparables aux grands modèles tout en réduisant la complexité et les coûts d'entraînement.

Son intégration facile et son efficacité en font un choix idéal pour les projets nécessitant une adaptation rapide aux nouvelles données textuelles.
